# わかばちゃんと学ぶサーバー監視
## CHAPTER1 そもそも監視って何？ なぜ必要なの？
### 監視が持つ4つの役割
- 見える化  
サーバーやネットワーク、システムリソースの状態を可視化する  
社内のメンバーなら「いつでも・誰でも」ログやデータが見られるようにする  
- 通知  
インシデントが発生したときに即座に対応できるようにする  
- 原因特定  
各種ログやデータを日頃から取得しておくことで、問題が起きたときに原因を切り分け、特定できる  
- 予防  
過去データを蓄積することで、傾向を把握し、次回のトラブルを予防する  

### 監視の目的  
サービスを通してユーザーに価値を届けること

### サーバーが「重い・軽い」とは？  
サーバーソフトウェアとI/OやCPUといったリソースの兼ね合いで変化する

### ユーザー視点で監視する  
一番簡単な監視は「今、ユーザーから見て、そのサービスが使えるのか？」ということ

### Linux vmstatコマンド
- procs
  - r：ランタイム待ちのプロセス数。通常は0～2程度。
  - b：割り込み不可能なスリープ状態にあるプロセス数。通常は0～2程度。
- memory
  - swpd：仮想メモリの量(KB)。使用しているスワップ領域。
  - free：空きメモリの量(KB)。純粋に未使用状態のメモリの量。
  - buff：バッファに用いられているメモリの量(KB)。主にカーネルがバッファ領域として使用。
  - cache：キャッシュに用いられているメモリの量(KB)。
- swap
  - si：スワップ・イン。通常は0。
  - so：スワップ・アウト。通常は0。
- io
  - bi：HDDから読み込んだブロック数の秒間平均。
  - bo：HDDへ書き込んだブロック数の秒間平均。
- system
  - in：1秒あたりの割り込み回数。
  - cs：1秒当たりのコンテキストスイッチの回数。コンテキストスイッチ＝プログラム実行切り替え
- cpu
  - us：カーネルコード以外の実行時間(%)。一般のプログラム。
  - sy：カーネルコードの実行時間(%)。Linuxの処理。
  - id：アイドル時間(%)。
  - wa：IO待ち時間(%)。
  - st：stealの略。他のVMとCPUの取り合いで実行されなかった時間。

## CHAPTER2 進化する監視 - クラウド時代の監視とは
### クラウドネイティブモニタリング
- クラウド利用を前提として作られた監視システム
- ペットから家畜へ
  - 監視対象を動的に構成
  - オーケストレーションツールなどと連携し、監視対象を自動更新する
  - 監視システム側では、渡されたデータを使うようにし、個別対象の特定は不要

### サービスのアーキテクチャ
- モノシリック・アーキテクチャ
  - 切り分けできない1枚岩のシステム
  - 結合が強い
  - 依存しあっている
  - 構造がシンプルなので、従来の方法で監視しやすい
- マイクロサービス・アーキテクチャ
  - 複数の独立した機能を組み合わせることで、1つのアプリケーションとして動かしている
  - 疎結合
    - どれかの機能が止まっても、影響が局所的で済み、サービス全体が止まることはない
  - 構造が複雑になりがち => 監視も進化が必要（クラウドネイティブモニタリング）
- どちらが優れているということではなく、目的に合わせて選択する

### インフラ構成
- オンプレミス（自前サーバー）
  - ハードウェア
  - OS
  - ランタイム
  - アプリ
  - 関数
- IaaS(Infrastructure as a Service)
  - ハードウェア
  - Amazon Elastic Compute Cloud (EC2)、Azure IaaS、Google Compute Engine
- PaaS(Platform as a Service)
  - ハードウェア
  - OS
  - ランタイム
  - Google App Engine、IBM Cloud PaaS、Firebase、Heroku、Kintone
- FaaS(Function as a Service)
  - ハードウェア
  - OS
  - ランタイム
  - アプリ
  - Azure Functions、AWS Lambda、Google Cloud Platform の Cloud Functions

## CHAPETR3 監視のあるある問題と解決するための考え方
### 監視のあるある問題
- 形だけ真似してツールを使ってしまう  
  - カーゴ・カルト・サイエンス（積荷科学）
  - 成功例を真似て形だけ導入
- チェックボックス監視をしてしまう
  - 監視は役割でなくスキル
  - 属人化させず、全員が持つべきスキル
  - チェックのみで障害時の理由や対策がわからない
- 監視ツールが複雑すぎて、担当者以外に操作できない
- メトリクスの取得頻度が少なすぎる（5分以上）
- 過去のログを保存していない
- 壊れやすいシステムを監視で支えている
- アラートが狼少年化している

### 解決策
- 監視サービスを部品化する
- データ収集
  - Pull型
    - 監視サーバーから、監視対象へ情報を取りに行く
    - 監視サーバー側で設定ファイルを書く
    - 監視対象にアクセス権限が必要になる場合がある
  - Push型
    - 監視対象から監視サーバーへ、情報が送られてくるようにする
    - 監視対象にエージェントをインストール => 監視対象が自発的に監視用データを送信
- データの種類
  - メトリクス
    - カウンタ：増加していく値（累計訪問者など）
    - ゲージ：ある時点の値（ロードアベレージ、CPU使用率など）
  - ログ
    - システムの活動記録（Linuxサーバー：syslog）
      - 非構造ログ
      - 構造化ログ（JSON形式など）
- 可視化
  - 集めたデータを分かりやすく表示
- 分析レポート
  - 傾向変化からリスクを異常を早期に検知
- アラート
  - アラートの改善
    - アラートのログを取る => 解析
    - 緊急度に応じ送信タイミングを変える
    - 自動化できるものは自動化する
    - 自動化できないものは、対処法をメッセージに記入
- いつでも・だれでも見たい数値を確認できるようにする
  - 監視画面はシンプルでわかりやすく
  - カスタマイズ性も大事

## CHAPTER4 統計の基本を学ぼう
### 算術平均(mean)
- 集合の全ての値を足して、集合の要素数で割った値
- その集合がどのようなものかを表すことができる

### 移動平均(moving average)
- 最近取得したデータポイント群で平均を計算した値
- 変化の傾向を把握しやすくする
- 平滑化しすぎると重要なデータポイントを見落とす可能性があり

### 中央値
- データを大きい順に並べたとき、真ん中の値
- データ数が偶数の時は、中央の値を足して2で割ったもの
- 異様に大きかったりちいさかったりするデータがある場合、平均より中央値が有効

### パーセンタイル値
- データの個数に着目し、パーセントで順位を表す値
- 外れ値を無視してサービス品質を評価できる（突発的なイレギュラーに影響されず、大局を見る）
- 残りの値を捨てているので、最大値が高すぎる場合も加味する必要がある

### 標準偏差
- 分散を平方根にとることによって求められる値
- データや確率変数の散らばり具合を表す
- 非正規分布には標準偏差を適用できない

## CHAPTER5～8 監視ツールの選び方など
### 代表的な監視ツール
- [Nagios](https://www.nagios.org/)
  - Pull型
  - 監視サーバー：オンプレミスが基本
  - OSS
- [Zabbix](https://www.zabbix.com/jp)
  - Pull型
  - 監視サーバー：オンプレミスが基本
  - OSS
- [Datadog](https://www.datadoghq.com/ja/)
  - Push型
  - 監視サーバー：SaaS
  - 有料サービス
- [New Relic](https://newrelic.com/jp)
  - Push型
  - 監視サーバー：SaaS
  - 有料サービス
- [Prometheus](https://prometheus.io/)
  - Pull型
  - 監視サーバー：オンプレミスが基本
  - OSS
- [Mackerel](https://ja.mackerel.io/)
  - Push型
  - 監視サーバー：SaaS
  - 有料サービス

### オンプレミスとSaaSの比較
- オンプレミス型監視ツール
  - 監視ツールの環境構築・インストールが必要
  - アップデート対応が必要
  - サーバーメンテナンスが必要
  - 監視サーバーの監視サーバーも必要
- SaaS型監視ツール
  - オンプレミスで必要な項目はサービス側で対応

### 監視項目
- ロードアベレージ
  - 実行待ちプロセス＋I/O待ちプロセス
  - 右肩上がりで一定値を超える場合は注意
- CPU
  - 使用率が高すぎも低すぎも注意
  - ロードアベレージ上昇のボトルネックを探る手掛かり
- メモリ
  - Webアプリではスワップは負け
  - 空き容量に注意
- DISK
  - IOPS(Input Output per Second)でデータ読み書き速度
  - DB、ストレージで注意が必要（HW性能）
- Interface
  - ネットワーク帯域の使用状況
  - 使用量チェック
  - DoS攻撃検知
- FileSystem
  - 空き容量の枯渇に注意

### アラートの設定
- 重要度
  - 重要度が低いもの：記録を残したいのでメールのみ
  - 重要度が中程度のもの：SlackやLINEに通知
  - 重要度が高く、即対応：電話、SMSに通知できるTwilioで通知
- 通知内容
  - 対応方法、手順書などを書いておくと対応が早くできる

## CHAPTER9 オブザーバビリティって最近よく聞くけど何？
### オブザーバビリティとは
- オブザーバビリティ（可観測性）
  - モニタリング（正常性）＋テスティング（異常検知） => システム全体を安定稼働

### テストの分類
- プリプロダクション
  - ユニットテスト：単体での動作を検証
  - コンポーネントテスト：各コンポーネント間のつながりが正しいかどうか検証
  - ファンクショナルテスト：外部のAPIやDBと連結して動作を検証する
  - Lintテスト：コードの表記揺れ、曖昧な記述を修正
  - UI/UXテスト：スタート～ゴールまでユーザーがたどり着けるか検証
- デプロイ
  - インテグレーションテスト：複数のシステムを合体させ動作を検証
  - 負荷テスト：大量のアクセス、データ処理など高負荷での挙動を検証
- リリース
  - カナリアリリース：一部のユーザーのみを新バージョンに上げる
  - フィーチャフラグ：機能を個別にOn/Offできる管理機構。
- ポストリリース
  - カオステスト：本番環境にわざと障害を起こし、対応力を向上させる
  - A/Bテスト：A/Bパターンの比較を行う

### オブザーバビリティの要素
- ログ：いつ・誰が・何をしたかの記録
- メトリクス：定期的に取得された値の集合
- トレース：独立したコンポーネントのやり取り（分散トレーシングシステム）
- イベントログ：システムに起こった出来事や行われた操作などを時系列に記録したデータ

### オブザーバビリティの成熟度（New Relic社のモデル）
- 0.Getting Started：計測を始める
  - まずは基本的な項目を計測してみる
- 1.Reactive：受動的対応
  - アラートに対応する
    - アラートに気付けているか
    - 障害対応はすばやくできているか
    - アラートのブラッシュアップ
- 2.Proactive：積極的対応
  - より踏み込んで対処する
    - 先回りして、問題になりそうな要素をつぶしていく
    - よりパフォーマンスを上げられないか
- 3.Predictive：予測的対応
  - ちょうど良いスケーリングの具合を探す
  - わざとデータベースを壊す、一部のサービスを止めるなど、カオステストを実施
  - 実験的なデプロイを行う
  - ログやメトリクスの傾向から将来発生しうる問題や障害を先回りして対応する
  - この段階にきて、コスト削減に繋げられる
- 4.Data Driven：データ駆動
  - オブザーバビリティで得られるデータをもとに、ビジネス指標(KPI)、顧客満足度の改善、向上につなげる
  - バグの修正や新機能の追加
  - デプロイによる効果を正しく評価する
  - ネットスコアなどの中長期的改善で顧客満足度を向上させる
  